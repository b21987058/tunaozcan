# -*- coding: utf-8 -*-
"""visionAssignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aWgmF0XmDZ1kWUxiHL4XyXe9VG_ZKfK0

**Introduction and Problem Definition**

In this assignment, we deal with edge detection techniques and focus on license plate detection using the Hough Transform. Edge detection serves as a  process that enabling the extraction of significant  edges, which means crucial shape information within an image.

The primary objective of this project is to implement two  edge detection methods: the Sobel Edge Detector and the Canny Edge Detector. These methods are for extracting edge points from images, which are then utilized in the Hough Transform for license plate detection.

The Hough Transform is for detecting potential line objects within the edge map generated by the previously defined detectors. By analyzing the distribution, this method enables the identification of possible plate regions within the image.

Through this assignment, we aim to implement edge detection algorithms and understanding the Hough Transform for object detection tasks.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy import ndimage
import xml.etree.ElementTree as ET
import os
import math

"""This block of the code enables us to unzip the given dataset and extract the two crucial folders for this assignment: "annotations" and "images". After building this unzipping part of the code into a different cell, one time running is enough for our duty. After one running the files are set to be in  our file hierarchy."""

# Commented out IPython magic to ensure Python compatibility.
!unzip dataset.zip
# %ls

"""This code segment loads a dataset from separate directories. It defines paths for images, annotations, and output directories. It retrieves a "sorted" list of image files from the specified directory."""

# Load dataset from separate directories
images_path = "images"  # Directory containing images
annotations_path = "annotations"  # Directory containing annotations
output_path = "output"

# Get list of image files
image_files = sorted(os.listdir(images_path))

"""**Edge Detection Using Sobel and Canny Algorithms**

***Sobel_edge_detector***:

This code defines a function sobel_edge_detector that applies the Sobel edge detection method to an input image. It computes the gradient magnitude of the image using Sobel kernels for horizontal and vertical edges. The resulting edge map is obtained by applying a specified threshold to the gradient magnitude. Finally, the edge map is returned as a binary image where edges are represented as white pixels.



***Canny_edge_detector:***

This code defines functions for implementing the Canny Edge Detector algorithm, a widely used method for edge detection in digital car plates images in several steps:

-Gaussian Blur (gaussian_blur): Applies Gaussian smoothing to the input image, reducing noise and preparing it for edge detection.

-Gradient Calculation (gradient): Computes the gradient magnitude and direction of the blurred image using Sobel operators, which highlight edges in horizontal and vertical directions.

-Non-Maximum Suppression (non_maximum_suppression): Suppresses non-maximum points in the gradient direction to obtain thin edges, ensuring that only the most significant edges are preserved.

-Hysteresis Thresholding (hysteresis_thresholding): Applies dual thresholding to identify strong and weak edge pixels, followed by edge tracking to connect weak edges to strong edges.

-Canny Edge Detector (canny_edge_detector): Uses the above steps to produce the final edge map of the input image based on specified low and high thresholds, along with an optional kernel size for Gaussian blurring.







"""

def sobel_edge_detector(image, threshold=30):
    # Sobel kernels
    sobel_x = np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]])

    sobel_y = np.array([[-1, -2, -1],
                        [0, 0, 0],
                        [1, 2, 1]])

    # Ensure input image is in float format for gradient calculation
    image = image.astype(float)

    # Convolve the image with the Sobel kernels
    grad_x = ndimage.convolve(image, sobel_x)
    grad_y = ndimage.convolve(image, sobel_y)

    # Compute gradient magnitude
    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)

    # Apply thresholding
    edge_map = np.uint8(gradient_magnitude > threshold) * 255

    return edge_map

def gaussian_blur(image, kernel_size):
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)

def gradient(image):
    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)
    gradient_direction = np.arctan2(sobely, sobelx)
    return gradient_magnitude, gradient_direction

def non_maximum_suppression(gradient_magnitude, gradient_direction):
    M, N = gradient_magnitude.shape
    suppressed = np.zeros_like(gradient_magnitude)
    angle = gradient_direction * 180. / np.pi
    angle[angle < 0] += 180

    for i in range(1, M - 1):
        for j in range(1, N - 1):
            q = 255
            r = 255
            # Angle 0
            if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):
                q = gradient_magnitude[i, j+1]
                r = gradient_magnitude[i, j-1]
            # Angle 45
            elif (22.5 <= angle[i, j] < 67.5):
                q = gradient_magnitude[i-1, j+1]
                r = gradient_magnitude[i+1, j-1]
            # Angle 90
            elif (67.5 <= angle[i, j] < 112.5):
                q = gradient_magnitude[i+1, j]
                r = gradient_magnitude[i-1, j]
            # Angle 135
            elif (112.5 <= angle[i, j] < 157.5):
                q = gradient_magnitude[i-1, j-1]
                r = gradient_magnitude[i+1, j+1]

            if (gradient_magnitude[i, j] >= q) and (gradient_magnitude[i, j] >= r):
                suppressed[i, j] = gradient_magnitude[i, j]
            else:
                suppressed[i, j] = 0
    return suppressed

def hysteresis_thresholding(image, low_threshold, high_threshold):
    high_threshold = image.max() * high_threshold
    low_threshold = high_threshold * low_threshold
    M, N = image.shape
    result = np.zeros((M, N), dtype=np.uint8)

    weak = 50
    strong = 255

    strong_i, strong_j = np.where(image >= high_threshold)
    zeros_i, zeros_j = np.where(image < low_threshold)

    weak_i, weak_j = np.where((image <= high_threshold) & (image >= low_threshold))

    result[strong_i, strong_j] = strong
    result[weak_i, weak_j] = weak

    dx = [-1, -1, -1, 0, 0, 1, 1, 1]
    dy = [-1, 0, 1, -1, 1, -1, 0, 1]

    for i, j in zip(weak_i, weak_j):
        for k in range(8):
            ni, nj = i + dx[k], j + dy[k]
            if (ni >= 0 and nj >= 0 and ni < M and nj < N and result[ni, nj] == strong):
                result[i, j] = strong
                break
            else:
                result[i, j] = 0

    return result

def canny_edge_detector(image, low_threshold, high_threshold, kernel_size=5):
    blurred = gaussian_blur(image, kernel_size)
    gradient_magnitude, gradient_direction = gradient(blurred)
    suppressed = non_maximum_suppression(gradient_magnitude, gradient_direction)
    edges = hysteresis_thresholding(suppressed, low_threshold, high_threshold)
    return edges

"""This code defines a function load_annotation to parse an XML annotation file containing bounding box coordinates for objects in an image. It uses the ElementTree library to parse the XML file, extracting bounding box coordinates for each object listed in the file and returning them as a list of tuples, each representing a bounding box (xmin, ymin, xmax, ymax)."""

def load_annotation(annotation_file):
    tree = ET.parse(annotation_file)
    root = tree.getroot()
    bboxes = []
    for obj in root.findall('.//object'):
        bbox = obj.find('.//bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        bboxes.append((xmin, ymin, xmax, ymax))
    return bboxes

"""
**Hough Transform (hough_transform):**

This function performs the Hough Transform on an edge map to detect lines.
It initializes an accumulator array to store votes for potential lines based on their rho and theta parameters.
It iterates through edge points in the edge map and accumulates votes in the accumulator array.
The accumulator array is then analyzed to find peaks, indicating potential lines.


**Detect Rectangles (detect_rectangles):**

This function takes a list of lines detected by the Hough Transform and identifies intersecting pairs that form rectangles.
It iterates through combinations of lines, checking for intersections between them.
If an intersection is found and it forms a closed shape with four points, it is considered a rectangle, and its coordinates are added to the list of rectangles.


**Line Intersection (line_intersection):**

This function calculates the intersection point of two lines given their endpoints.
It takes two lines defined by their endpoints and computes the intersection point using the method of determinants.
If the lines are parallel, it returns None, indicating no intersection.
Otherwise, it returns the coordinates of the intersection point as integers."""

def hough_transform(edge_map, threshold=50):
    rho_max = int(np.ceil(np.sqrt(edge_map.shape[0] ** 2 + edge_map.shape[1] ** 2)))
    theta_max = 180

    accumulator = np.zeros((rho_max, theta_max), dtype=np.uint8)

    # Get indices of edge points
    edge_points = np.argwhere(edge_map > 0)

    for point in edge_points:
        for theta in range(theta_max):
            rho = int(point[1] * np.cos(np.deg2rad(theta)) + point[0] * np.sin(np.deg2rad(theta)))
            accumulator[rho, theta] += 1

    # Find peaks in the accumulator
    lines = np.argwhere


def detect_rectangles(lines):
    rectangles = []
    if lines is not None:
        lines = np.squeeze(lines)
        for line1 in lines:
            for line2 in lines:
                if line1 is not line2:
                    intersection = line_intersection(line1, line2)
                    if intersection is not None and len(intersection) == 4:
                        rectangles.append(intersection)
    return rectangles


def line_intersection(line1, line2):
    x1, y1, x2, y2 = line1
    x3, y3, x4, y4 = line2

    denominator = ((x1 - x2) * (y3 - y4)) - ((y1 - y2) * (x3 - x4))

    if denominator == 0:
        return None  # Parallel lines

    x = (((x1 * y2 - y1 * x2) * (x3 - x4)) - ((x1 - x2) * (x3 * y4 - y3 * x4))) / denominator
    y = (((x1 * y2 - y1 * x2) * (y3 - y4)) - ((y1 - y2) * (x3 * y4 - y3 * x4))) / denominator

    return int(x), int(y)

"""
This block of code iterates through each image in a dataset, performing the following steps for each image:

**Load Image and Annotation:**

It loads the image and corresponding annotation file containing bounding box coordinates for objects in the image.

**Preprocessing:**

Converts the loaded image to grayscale, necessary for edge detection algorithms.

**Edge Detection:**

Applies both Sobel and Canny edge detection algorithms to the grayscale image, obtaining edge maps highlighting regions of significant gradient change.

**Hough Transform:**

Utilizes the Hough Transform on the edge maps to detect potential lines, which could correspond to the edges of rectangular plates.

**Rectangle Detection:**

Detects rectangles based on the lines obtained from the Hough Transform for both Sobel and Canny edge detection results.

**Visualize Detected Rectangles:**

Draws rectangles representing detected plates on copies of the original images.

**Save Output Images:**

Saves the images with detected rectangles in the specified output directory.

**Display Results:**

Displays a visual comparison of the original image, edge detection results (Sobel and Canny), and the images with detected rectangles overlaid for both Sobel and Canny methods.
This iterative process allows for the detection and visualization of potential license plate regions within the dataset images, facilitating assessment of the effectiveness of the edge detection algorithms and the Hough Transform for this task."""

# Iterate through images
for image_file in image_files:
    # Load image
    image_path = os.path.join(images_path, image_file)
    image = cv2.imread(image_path)

    # Load annotation
    annotation_file = os.path.splitext(image_file)[0] + ".xml"
    annotation_path = os.path.join(annotations_path, annotation_file)
    bboxes = load_annotation(annotation_path)

    # Convert image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Sobel edge detector
    sobel_edges = sobel_edge_detector(gray)

    # Apply Canny edge detector
    canny_edges = canny_edge_detector(gray, low_threshold=0.05, high_threshold=0.15)

    # Hough Transform for rectangle detection
    sobel_lines = hough_transform(sobel_edges)
    canny_lines = hough_transform(canny_edges)

    # Detect rectangular plates
    sobel_rectangles = detect_rectangles(sobel_lines)
    canny_rectangles = detect_rectangles(canny_lines)

    # Plot detected plates on the original image
    sobel_image_with_rectangles = image.copy()
    for rect in sobel_rectangles:
        cv2.rectangle(sobel_image_with_rectangles, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)

    canny_image_with_rectangles = image.copy()
    for rect in canny_rectangles:
        cv2.rectangle(canny_image_with_rectangles, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)

    # Save the images with detected rectangles
    sobel_output_path = os.path.join(output_path, "sobel_" + image_file)
    canny_output_path = os.path.join(output_path, "canny_" + image_file)
    cv2.imwrite(sobel_output_path, sobel_image_with_rectangles)
    cv2.imwrite(canny_output_path, canny_image_with_rectangles)

    # Display images
    sobel_image = cv2.cvtColor(sobel_image_with_rectangles, cv2.COLOR_BGR2RGB)
    canny_image = cv2.cvtColor(canny_image_with_rectangles, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(16, 8))

    # Original image
    plt.subplot(231)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title("Original Image")
    plt.axis('off')

    # Sobel edge detection
    plt.subplot(232)
    plt.imshow(sobel_edges, cmap='gray')
    plt.title("Sobel Edge Detection")
    plt.axis('off')

    # Canny edge detection
    plt.subplot(233)
    plt.imshow(canny_edges, cmap='gray')
    plt.title("Canny Edge Detection")
    plt.axis('off')

    # Sobel edge detection with detected rectangles
    plt.subplot(235)
    plt.imshow(sobel_image)
    plt.title("Sobel with Rectangles")
    plt.axis('off')
     # Canny edge detection with detected rectangles
    plt.subplot(236)
    plt.imshow(canny_image)
    plt.title("Canny with Rectangles")
    plt.axis('off')

    plt.tight_layout()
    plt.show()